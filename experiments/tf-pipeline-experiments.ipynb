{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out estimators with our custom input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# standard library\n",
    "import itertools\n",
    "import sys, os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from collections import OrderedDict\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# tesnsorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# local imports\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "from tf_utils import make_csv_pipeline, make_csv_col_tensors\n",
    "\n",
    "# this styling is purely my preference\n",
    "# less chartjunk\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'line.linewidth': 2.5})\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depth', 'sibling_pos', 'no_classes', 'id_len', 'class_len']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll initiate a simple pipeline that takes 2 csv files\n",
    "df = pd.read_csv('../data/final/cleaneval/dom-full-00.csv', nrows=10)\n",
    "feature_cols = list(filter(lambda x: x not in ['url', 'path', 'content_label'], df.columns))\n",
    "label_cols = ['content_label']\n",
    "\n",
    "feature_cols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    feature_tens, label_tens, = make_csv_pipeline(csv_files=['../data/final/cleaneval/dom-full-00.csv', '../data/final/cleaneval/dom-full-00.csv'],\n",
    "                                                  feature_cols=feature_cols, label_cols=label_cols, num_epochs=20, batch_size=1000)\n",
    "\n",
    "    return {'x': feature_tens}, label_tens\n",
    "\n",
    "def test_input_fn():\n",
    "    feature_tens, label_tens, = make_csv_pipeline(csv_files=['../data/final/cleaneval/dom-full-00.csv', '../data/final/cleaneval/dom-full-00.csv'],\n",
    "                                                  feature_cols=feature_cols, label_cols=label_cols, num_epochs=1, batch_size=1000, shuffle=False)\n",
    "\n",
    "    return {'x': feature_tens}, label_tens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tensors we should be able to just return them from a function and pass them to an estimator. To start with, we'll pass them to a simple linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpc55tgrni\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9819a16a58>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpc55tgrni'}\n"
     ]
    }
   ],
   "source": [
    "tf_feat_cols = [\n",
    "    tf.feature_column.numeric_column('x', shape=(len(feature_cols)))\n",
    "]\n",
    "estiamtor = tf.contrib.learn.DNNClassifier(feature_columns=tf_feat_cols, hidden_units=(1000, 500, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpc55tgrni/model.ckpt.\n",
      "INFO:tensorflow:loss = 53.9072, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.238298\n",
      "INFO:tensorflow:loss = 5.5348, step = 101 (419.645 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 144 into /tmp/tmpc55tgrni/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.238272\n",
      "INFO:tensorflow:loss = 1.91086, step = 201 (419.689 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 287 into /tmp/tmpc55tgrni/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.238226\n",
      "INFO:tensorflow:loss = 0.733354, step = 301 (419.769 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 364 into /tmp/tmpc55tgrni/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.13644.\n",
      "CPU times: user 1h 47min 20s, sys: 1min, total: 1h 48min 20s\n",
      "Wall time: 25min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x7f98062857f0>, 'hidden_units': (1000, 500, 200), 'feature_columns': (_NumericColumn(key='x', shape=(1572,), default_value=None, dtype=tf.float32, normalizer_fn=None),), 'optimizer': None, 'activation_fn': <function relu at 0x7f980537bd90>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train it\n",
    "estiamtor.fit(input_fn=input_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-27-18:38:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpc55tgrni/model.ckpt-364\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-27-18:40:55\n",
      "INFO:tensorflow:Saving dict for global step 364: accuracy = 0.844611, accuracy/baseline_label_mean = 0.143667, accuracy/threshold_0.500000_mean = 0.844611, auc = 0.544095, auc_precision_recall = 0.171649, global_step = 364, labels/actual_label_mean = 0.143667, labels/prediction_mean = 0.104894, loss = 1.18294, precision/positive_threshold_0.500000_mean = 0.242054, recall/positive_threshold_0.500000_mean = 0.0382831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.84461111,\n",
       " 'accuracy/baseline_label_mean': 0.14366667,\n",
       " 'accuracy/threshold_0.500000_mean': 0.84461111,\n",
       " 'auc': 0.54409468,\n",
       " 'auc_precision_recall': 0.17164919,\n",
       " 'global_step': 364,\n",
       " 'labels/actual_label_mean': 0.14366667,\n",
       " 'labels/prediction_mean': 0.10489396,\n",
       " 'loss': 1.1829363,\n",
       " 'precision/positive_threshold_0.500000_mean': 0.24205379,\n",
       " 'recall/positive_threshold_0.500000_mean': 0.038283061}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estiamtor.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c13661454f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "tf.verify_tensor_all_finite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_dict = make_csv_col_tensors(csv_files=['../data/final/cleaneval/dom-full-00.csv', '../data/final/cleaneval/dom-full-00.csv'], \n",
    "                                 shuffle=True, num_epochs=None, csv_decoder_kwargs={'convert_ints': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Gather_11:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_tens, sibling_pos = tens_dict['depth'], tens_dict['sibling_pos']\n",
    "depth_pred = tf.greater(depth_tens, [6])\n",
    "selected_items = tf.reshape(tf.where(depth_pred), [-1])\n",
    "\n",
    "found = tf.gather(tf.reshape(tf.stack([depth_tens, sibling_pos]), [-1, 2]), selected_items)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[5.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[4.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[5.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[5.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[6.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[6.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[4.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[5.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,   7.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,  11.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,  24.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,  36.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,  54.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[13.0, array([[ 13.,   1.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[12.0, array([[ 12.,  30.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[7.0, array([[ 7.,  0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[5.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[6.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[4.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[11.0, array([[ 11.,  19.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[12.0, array([[ 12.,   7.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[5.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[4.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[10.0, array([[ 10.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[17.0, array([[ 17.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[13.0, array([[ 13.,  53.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[14.0, array([[ 14.,   5.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[15.0, array([[ 15.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[4.0, array([], shape=(0, 2), dtype=float32)]\n",
      "\n",
      "=======\n",
      "[7.0, array([[ 7.,  0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[7.0, array([[ 7.,  1.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[17.0, array([[ 17.,   1.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[16.0, array([[ 16.,  14.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[16.0, array([[ 16.,  22.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[12.0, array([[ 12.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[14.0, array([[ 14.,   1.]], dtype=float32)]\n",
      "\n",
      "=======\n",
      "[14.0, array([[ 14.,   0.]], dtype=float32)]\n",
      "\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # variables must be initialized otherwise it fails \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    # test the output\n",
    "    for _ in range(40):\n",
    "        print(sess.run([depth_tens, found]))\n",
    "        print(\"\\n=======\") \n",
    "\n",
    "    # finish\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack_1:0' shape=(2,) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([depth_tens, sibling_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
