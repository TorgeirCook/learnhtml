{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural model with the new, simplified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# standard library\n",
    "import itertools\n",
    "import sys, os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import functools\n",
    "import math\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "from scipy import sparse\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# skealrn\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, GroupKFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "# tesnsorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adagrad, SGD\n",
    "from keras import activations\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "# local imports\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "import tf_utils, tf_experiments\n",
    "from utils import dict_combinations, RecDict, ItemSelector, MyKerasClassifier\n",
    "from keras_utils import KerasSparseClassifier, create_model, sparse_generator\n",
    "\n",
    "# this styling is purely my preference\n",
    "# less chartjunk\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'line.linewidth': 2.5})\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'tensorflow' == K.backend():\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some constants\n",
    "# RANDOM_SEED = 41\n",
    "np.random.seed()\n",
    "tf.set_random_seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_argsort(x, shuffle=True):\n",
    "    \"\"\"Sortng function that preserves grouping of elements. \n",
    "    Same kind elements stay together, but the groups may be shuffled if specified.\"\"\"\n",
    "    uniq_elems = np.unique(x)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(uniq_elems)\n",
    "\n",
    "    # get the indices for each unique item\n",
    "    new_indices = np.zeros(x.shape, dtype=int)\n",
    "    current_pos = 0\n",
    "    for elem in uniq_elems:\n",
    "        elem_indices = np.where(x == elem)[0]  # the positions of elem\n",
    "        new_indices[current_pos:current_pos + len(elem_indices)] = elem_indices\n",
    "        current_pos += len(elem_indices)\n",
    "    \n",
    "    return new_indices\n",
    "\n",
    "vals = np.array([1, 0, 2, 1, 1, 0, 1])\n",
    "vals[group_argsort(vals, shuffle=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputting Dragnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/dask/local.py:270: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  args2 = [_execute_task(a, cache) for a in args]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf_utils.get_numpy_dataset('../data/final/dragnet/dom-full-*.csv', text_cols=['class_text', 'id_text', 'block_text'], categorize_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['text'][dataset['text'] != dataset['text']] = ''  # to fix the nan problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case_split(identifier):\n",
    "    # split text on camel case\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return ' '.join([m.group(0) for m in matches])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return  ' ' + camel_case_split(text.replace('_', '-').replace('-', ' ')).lower() + ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple keras model(no sklearn compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_block = dataset['is_block'].ravel()\n",
    "data_X = RecDict({'numeric': dataset['numeric'][is_block], 'text': dataset['text'][is_block, 0]})\n",
    "data_y = dataset['y'][is_block]\n",
    "groups = dataset['id'][is_block, 0]  # for the url\n",
    "\n",
    "# transform pipeline(the sklearn pipeline but without estimation)\n",
    "tr_pipeline = Pipeline(steps=[\n",
    "    ('union', FeatureUnion(transformer_list=[\n",
    "        ('numeric', Pipeline(steps=[\n",
    "            ('select', ItemSelector(key='numeric')),\n",
    "        ])),\n",
    "        ('class', Pipeline(steps=[\n",
    "            ('select', ItemSelector(key='text')),\n",
    "            ('text', TfidfVectorizer(analyzer='char_wb', ngram_range=(3,3), use_idf=False,\n",
    "                                     preprocessor=preprocess_text))\n",
    "        ]))],\n",
    "        transformer_weights={\n",
    "            'numeric': 1.0,\n",
    "            'class': 1.0\n",
    "        },\n",
    "    )),\n",
    "    ('normalizer', MaxAbsScaler())\n",
    "]) \n",
    "\n",
    "# tranform the data\n",
    "data_X = tr_pipeline.fit_transform(data_X, data_y)\n",
    "\n",
    "# order them by group, for consistency\n",
    "order = group_argsort(groups)\n",
    "groups = groups[order]\n",
    "data_X = data_X[order]\n",
    "data_y = data_y[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([     0,      1,      2, ..., 114251, 114252, 114253]),\n",
       " array([114254, 114255, 114256, ..., 126251, 126252, 126253]),\n",
       " array([  2500,   2501,   2502, ..., 125806, 125807, 125808])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # get the splits(train, validation, test)\n",
    "# splitter = GroupKFold(10).split(data_X, data_y, groups=groups)\n",
    "# split_slices = [0, 0, 0]\n",
    "# split_slices[2] = next(splitter)[1]\n",
    "# split_slices[1] = next(splitter)[1]\n",
    "\n",
    "# # get the rest\n",
    "# split_slices[0] = np.ones(data_X.shape[0], dtype=bool)\n",
    "# split_slices[0][split_slices[2]] = False\n",
    "# split_slices[0][split_slices[1]] = False\n",
    "\n",
    "# split_slices\n",
    "\n",
    "splitter = GroupKFold(10).split(data_X, data_y, groups=groups)\n",
    "split_slices = [0, 0, 0]\n",
    "split_slices[2] = next(splitter)[1]\n",
    "\n",
    "# # get the rest\n",
    "rest = np.ones(data_X.shape[0], dtype=bool)\n",
    "rest[split_slices[2]] = False\n",
    "rest_ind = np.nonzero(rest)[0]\n",
    "\n",
    "split_ind = int(rest_ind.shape[0] * .9)\n",
    "split_slices[1] = rest_ind[split_point:]\n",
    "split_slices[0] = rest_ind[:split_point]\n",
    "\n",
    "split_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the metrics\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, validation_data, batch_size, *args,  prefix='', **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._validation_data = validation_data\n",
    "        self._batch_size = batch_size\n",
    "        self.prefix = prefix\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        preds = self.model.predict_generator(\n",
    "            sparse_generator(self._validation_data[0], None, self._batch_size, shuffle=False),\n",
    "            steps=np.ceil(self._validation_data[0].shape[0] / self._batch_size)\n",
    "        )\n",
    "\n",
    "        predict = np.round(np.asarray(preds))\n",
    "        target = self._validation_data[1]\n",
    "        results = {\n",
    "            'precision': precision_score(target, predict),\n",
    "            'recall': recall_score(target, predict),\n",
    "            'f1': f1_score(target, predict)\n",
    "        }\n",
    "        print(' - '.join('{}{}: {}'.format(self.prefix, name, val) for name, val in results.items()))\n",
    "        \n",
    "        for name, val in results.items():\n",
    "            logs['{}{}'.format(self.prefix, name)] = val \n",
    "        \n",
    "metrics = Metrics((data_X[split_slices[1]], data_y[split_slices[1]]), 1024, prefix='val_')\n",
    "metrics_train = Metrics((data_X[split_slices[0]], data_y[split_slices[0]]), 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83553384, 1.24508133])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the weights\n",
    "weights = class_weight.compute_class_weight('balanced', [0, 1], data_y[split_slices[0]])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the callbacks and the model\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('/home/nikitautiu/models/keras/weights.best.hdf5', \n",
    "                                             monitor='val_f1', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopper = keras.callbacks.EarlyStopping(monitor='val_f1', min_delta=0.0001, patience=50, verbose=1, mode='max')\n",
    "                            \n",
    "    \n",
    "model = create_model(nb_features=data_X.shape[1], optimizer='rmsprop', hidden_layers=[1000, 500, 100],\n",
    "                     activation='relu', dropout=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.2536 - acc: 0.8960 - val_loss: 0.2131 - val_acc: 0.9258\n",
      "recall: 0.892300574656667 - precision: 0.9292742303595882 - f1: 0.9104121636729523\n",
      "val_recall: 0.8690361213057756 - val_precision: 0.930506721820062 - val_f1: 0.8987215341590091\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.89872, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.1701 - acc: 0.9344 - val_loss: 0.3061 - val_acc: 0.8815\n",
      "recall: 0.9365686179020162 - precision: 0.9345206278244813 - f1: 0.935543502055311\n",
      "val_recall: 0.9136565578520378 - val_precision: 0.9307359307359307 - val_f1: 0.9221171654157325\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.89872 to 0.92212, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.1450 - acc: 0.9448 - val_loss: 0.1709 - val_acc: 0.9297\n",
      "recall: 0.9501314892373625 - precision: 0.9398333253046871 - f1: 0.9449543506163273\n",
      "val_recall: 0.9200309059300753 - val_precision: 0.9342879560612005 - val_f1: 0.9271046228710463\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.92212 to 0.92710, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1302 - acc: 0.9516 - val_loss: 0.1344 - val_acc: 0.9479\n",
      "recall: 0.9497175416382585 - precision: 0.9518730933496035 - f1: 0.9507940957790427\n",
      "val_recall: 0.9235078230635503 - val_precision: 0.9527700278995616 - val_f1: 0.9379107405590975\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.92710 to 0.93791, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.1189 - acc: 0.9569 - val_loss: 0.1547 - val_acc: 0.9251\n",
      "recall: 0.9617707217298139 - precision: 0.9498821605502381 - f1: 0.9557894736842105\n",
      "val_recall: 0.9439830017384586 - val_precision: 0.9439830017384586 - val_f1: 0.9439830017384586\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.93791 to 0.94398, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.1114 - acc: 0.9595 - val_loss: 0.1598 - val_acc: 0.9414\n",
      "recall: 0.9749439953248271 - precision: 0.928828264551001 - f1: 0.9513275913275914\n",
      "val_recall: 0.953834266949971 - val_precision: 0.9221288515406163 - val_f1: 0.9377136346372958\n",
      "\n",
      "Epoch 00006: val_f1 did not improve\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.1051 - acc: 0.9625 - val_loss: 0.1071 - val_acc: 0.9668\n",
      "recall: 0.9588730885360864 - precision: 0.9634006116207952 - f1: 0.9611315182504913\n",
      "val_recall: 0.925053119567317 - val_precision: 0.9545545146501894 - val_f1: 0.9395722974298607\n",
      "\n",
      "Epoch 00007: val_f1 did not improve\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.0994 - acc: 0.9648 - val_loss: 0.1012 - val_acc: 0.9740\n",
      "recall: 0.9530047725723191 - precision: 0.9686424947407499 - f1: 0.9607600063824825\n",
      "val_recall: 0.9306548193934712 - val_precision: 0.9576624925462135 - val_f1: 0.9439655172413793\n",
      "\n",
      "Epoch 00008: val_f1 did not improve\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.0946 - acc: 0.9667 - val_loss: 0.2805 - val_acc: 0.8861\n",
      "recall: 0.9595548845816694 - precision: 0.9655028788435625 - f1: 0.9625196927323132\n",
      "val_recall: 0.9264052540081128 - val_precision: 0.9529107887939599 - val_f1: 0.9394711067580802\n",
      "\n",
      "Epoch 00009: val_f1 did not improve\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0920 - acc: 0.9677 - val_loss: 0.1154 - val_acc: 0.9603\n",
      "recall: 0.9656910489919158 - precision: 0.96557349110121 - f1: 0.9656322664686332\n",
      "val_recall: 0.9391539501641878 - val_precision: 0.955957530475816 - val_f1: 0.947481243301179\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.94398 to 0.94748, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.0875 - acc: 0.9688 - val_loss: 0.1055 - val_acc: 0.9635\n",
      "recall: 0.9688321807733515 - precision: 0.966220646446004 - f1: 0.9675246513550647\n",
      "val_recall: 0.9455282982422252 - val_precision: 0.9584883493244566 - val_f1: 0.9519642162582652\n",
      "\n",
      "Epoch 00011: val_f1 improved from 0.94748 to 0.95196, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0865 - acc: 0.9694 - val_loss: 0.1168 - val_acc: 0.9368\n",
      "recall: 0.9674442388234148 - precision: 0.9669027280913095 - f1: 0.9671734076607553\n",
      "val_recall: 0.9439830017384586 - val_precision: 0.9601178781925344 - val_f1: 0.9519820785039447\n",
      "\n",
      "Epoch 00012: val_f1 improved from 0.95196 to 0.95198, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0838 - acc: 0.9706 - val_loss: 0.1330 - val_acc: 0.9492\n",
      "recall: 0.9681747345865394 - precision: 0.9670915016782604 - f1: 0.9676328149716483\n",
      "val_recall: 0.942437705234692 - val_precision: 0.9529296875 - val_f1: 0.947654656696125\n",
      "\n",
      "Epoch 00013: val_f1 did not improve\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0817 - acc: 0.9715 - val_loss: 0.1114 - val_acc: 0.9622\n",
      "recall: 0.9504967371189247 - precision: 0.9747540328622084 - f1: 0.9624725694701283\n",
      "val_recall: 0.9001352134440795 - val_precision: 0.9682110949511739 - val_f1: 0.9329329329329329\n",
      "\n",
      "Epoch 00014: val_f1 did not improve\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.0795 - acc: 0.9726 - val_loss: 0.0968 - val_acc: 0.9753\n",
      "recall: 0.968101685010227 - precision: 0.9703936930999976 - f1: 0.9692463340606297\n",
      "val_recall: 0.9509368360054086 - val_precision: 0.9632165916650361 - val_f1: 0.9570373250388804\n",
      "\n",
      "Epoch 00015: val_f1 improved from 0.95198 to 0.95704, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0783 - acc: 0.9725 - val_loss: 0.2332 - val_acc: 0.9186\n",
      "recall: 0.9718272134021623 - precision: 0.9624993970964163 - f1: 0.9671408146945502\n",
      "val_recall: 0.9685145837357543 - val_precision: 0.9494413936754402 - val_f1: 0.958883151654236\n",
      "\n",
      "Epoch 00016: val_f1 improved from 0.95704 to 0.95888, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0762 - acc: 0.9733 - val_loss: 0.1502 - val_acc: 0.9505\n",
      "recall: 0.9677607869874355 - precision: 0.9714271747366363 - f1: 0.9695905148753979\n",
      "val_recall: 0.9455282982422252 - val_precision: 0.9641520583021469 - val_f1: 0.9547493661010337\n",
      "\n",
      "Epoch 00017: val_f1 did not improve\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.0750 - acc: 0.9739 - val_loss: 0.1109 - val_acc: 0.9622\n",
      "recall: 0.9769163338852634 - precision: 0.9569925816377645 - f1: 0.9668518273065754\n",
      "val_recall: 0.9692872319876377 - val_precision: 0.9402285928424209 - val_f1: 0.9545368080654366\n",
      "\n",
      "Epoch 00018: val_f1 did not improve\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.0725 - acc: 0.9749 - val_loss: 0.1108 - val_acc: 0.9661\n",
      "recall: 0.9456267653647609 - precision: 0.9743338852927894 - f1: 0.959765711884932\n",
      "val_recall: 0.902066834073788 - val_precision: 0.9717020391177694 - val_f1: 0.9355905038565561\n",
      "\n",
      "Epoch 00019: val_f1 did not improve\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0724 - acc: 0.9747 - val_loss: 0.0995 - val_acc: 0.9714\n",
      "recall: 0.9403428460114931 - precision: 0.9757194471815862 - f1: 0.9577045643359331\n",
      "val_recall: 0.8922155688622755 - val_precision: 0.9716028607488431 - val_f1: 0.9302185077031518\n",
      "\n",
      "Epoch 00020: val_f1 did not improve\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0715 - acc: 0.9748 - val_loss: 0.1034 - val_acc: 0.9814\n",
      "recall: 0.9752848933476186 - precision: 0.968703896292355 - f1: 0.9719832554753384\n",
      "val_recall: 0.9638786942244543 - val_precision: 0.9585094122166731 - val_f1: 0.9611865549455841\n",
      "\n",
      "Epoch 00021: val_f1 improved from 0.95888 to 0.96119, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0701 - acc: 0.9756 - val_loss: 0.1162 - val_acc: 0.9694\n",
      "recall: 0.9684425830330184 - precision: 0.9749950970778584 - f1: 0.9717077937942828\n",
      "val_recall: 0.9464941085570794 - val_precision: 0.9712586719524281 - val_f1: 0.9587164938368227\n",
      "\n",
      "Epoch 00022: val_f1 did not improve\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0690 - acc: 0.9757 - val_loss: 0.2267 - val_acc: 0.9355\n",
      "recall: 0.9742378494204733 - precision: 0.9733372257091423 - f1: 0.9737873293255774\n",
      "val_recall: 0.9569248599575043 - val_precision: 0.9619417475728156 - val_f1: 0.9594267454246153\n",
      "\n",
      "Epoch 00023: val_f1 did not improve\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0685 - acc: 0.9761 - val_loss: 0.1259 - val_acc: 0.9570\n",
      "recall: 0.9679799357163729 - precision: 0.9747204786190663 - f1: 0.9713385134144554\n",
      "val_recall: 0.9534479428240293 - val_precision: 0.9633099141295862 - val_f1: 0.9583535579069993\n",
      "\n",
      "Epoch 00024: val_f1 did not improve\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.0675 - acc: 0.9766 - val_loss: 0.1118 - val_acc: 0.9720\n",
      "recall: 0.9758205902405767 - precision: 0.972505338769171 - f1: 0.9741601439058778\n",
      "val_recall: 0.9658103148541627 - val_precision: 0.9567546880979717 - val_f1: 0.9612611746611555\n",
      "\n",
      "Epoch 00025: val_f1 improved from 0.96119 to 0.96126, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0664 - acc: 0.9768 - val_loss: 0.1044 - val_acc: 0.9688\n",
      "recall: 0.9671763903769358 - precision: 0.9768334071122916 - f1: 0.9719809127615319\n",
      "val_recall: 0.9418582190457794 - val_precision: 0.9643987341772152 - val_f1: 0.9529952115704095\n",
      "\n",
      "Epoch 00026: val_f1 did not improve\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0651 - acc: 0.9776 - val_loss: 0.0651 - val_acc: 0.9811\n",
      "recall: 0.9755770916528684 - precision: 0.9737513671162961 - f1: 0.9746633744055077\n",
      "val_recall: 0.9542205910759127 - val_precision: 0.960528874197939 - val_f1: 0.9573643410852714\n",
      "\n",
      "Epoch 00027: val_f1 did not improve\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.0654 - acc: 0.9778 - val_loss: 0.1040 - val_acc: 0.9821\n",
      "recall: 0.9751387941949937 - precision: 0.9758754294904598 - f1: 0.975506972778759\n",
      "val_recall: 0.9546069152018544 - val_precision: 0.9633528265107213 - val_f1: 0.958959930144562\n",
      "\n",
      "Epoch 00028: val_f1 did not improve\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0645 - acc: 0.9779 - val_loss: 0.0996 - val_acc: 0.9727\n",
      "recall: 0.9739213012564527 - precision: 0.975251146006047 - f1: 0.9745857699805067\n",
      "val_recall: 0.9449488120533127 - val_precision: 0.9652722967640095 - val_f1: 0.9550024402147389\n",
      "\n",
      "Epoch 00029: val_f1 did not improve\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0631 - acc: 0.9783 - val_loss: 0.2000 - val_acc: 0.9375\n",
      "recall: 0.9792052206097205 - precision: 0.9706492879555877 - f1: 0.974908482629882\n",
      "val_recall: 0.9667761251690168 - val_precision: 0.959363618938087 - val_f1: 0.9630556090051953\n",
      "\n",
      "Epoch 00030: val_f1 improved from 0.96126 to 0.96306, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0627 - acc: 0.9782 - val_loss: 0.1363 - val_acc: 0.9544\n",
      "recall: 0.9706097204636213 - precision: 0.9730026606781068 - f1: 0.9718047174986286\n",
      "val_recall: 0.9567316978945335 - val_precision: 0.9683284457478006 - val_f1: 0.9624951418577535\n",
      "\n",
      "Epoch 00031: val_f1 did not improve\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0623 - acc: 0.9788 - val_loss: 0.1490 - val_acc: 0.9323\n",
      "recall: 0.9753092432063895 - precision: 0.9751192910702113 - f1: 0.975214257888586\n",
      "val_recall: 0.9484257291867877 - val_precision: 0.9625563614977456 - val_f1: 0.9554388013232146\n",
      "\n",
      "Epoch 00032: val_f1 did not improve\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0621 - acc: 0.9785 - val_loss: 0.1089 - val_acc: 0.9714\n",
      "recall: 0.9815671569104899 - precision: 0.9538355969902039 - f1: 0.9675027001080043\n",
      "val_recall: 0.9694803940506085 - val_precision: 0.9348109517601043 - val_f1: 0.9518300777545989\n",
      "\n",
      "Epoch 00033: val_f1 did not improve\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.0607 - acc: 0.9793 - val_loss: 0.0719 - val_acc: 0.9727\n",
      "recall: 0.978718223434304 - precision: 0.9711979896583386 - f1: 0.9749436049191064\n",
      "val_recall: 0.9675487734209002 - val_precision: 0.9651252408477842 - val_f1: 0.9663354876049001\n",
      "\n",
      "Epoch 00034: val_f1 improved from 0.96306 to 0.96634, saving model to /home/nikitautiu/models/keras/weights.best.hdf5\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0610 - acc: 0.9795 - val_loss: 0.1131 - val_acc: 0.9761\n",
      "recall: 0.980349663971949 - precision: 0.9705187542184939 - f1: 0.9754094388991181\n",
      "val_recall: 0.967741935483871 - val_precision: 0.9595862861520782 - val_f1: 0.9636468551644547\n",
      "\n",
      "Epoch 00035: val_f1 did not improve\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0609 - acc: 0.9793 - val_loss: 0.1243 - val_acc: 0.9681\n",
      "recall: 0.9788156228693874 - precision: 0.9752298697202746 - f1: 0.9770194562932176\n",
      "val_recall: 0.9594359667761252 - val_precision: 0.9669067549153202 - val_f1: 0.9631568741516386\n",
      "\n",
      "Epoch 00036: val_f1 did not improve\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0595 - acc: 0.9794 - val_loss: 0.1135 - val_acc: 0.9694\n",
      "recall: 0.9765510860037012 - precision: 0.9765510860037012 - f1: 0.9765510860037012\n",
      "val_recall: 0.9604017770909793 - val_precision: 0.9630060042610885 - val_f1: 0.9617021276595745\n",
      "\n",
      "Epoch 00037: val_f1 did not improve\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0597 - acc: 0.9793 - val_loss: 0.0982 - val_acc: 0.9720\n",
      "recall: 0.9805688127008864 - precision: 0.9691470927993839 - f1: 0.9748244977003148\n",
      "val_recall: 0.9605949391539501 - val_precision: 0.9561622764852913 - val_f1: 0.9583734823665446\n",
      "\n",
      "Epoch 00038: val_f1 did not improve\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.0593 - acc: 0.9795 - val_loss: 0.1186 - val_acc: 0.9479\n",
      "recall: 0.978864322586929 - precision: 0.9757992086802437 - f1: 0.9773293624263053\n",
      "val_recall: 0.9609812632798919 - val_precision: 0.9583895203236371 - val_f1: 0.9596836419753086\n",
      "\n",
      "Epoch 00039: val_f1 did not improve\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.0589 - acc: 0.9800 - val_loss: 0.1127 - val_acc: 0.9733\n",
      "recall: 0.9741161001266193 - precision: 0.9776392961876833 - f1: 0.9758745182221789\n",
      "val_recall: 0.9474599188719336 - val_precision: 0.9623307828134197 - val_f1: 0.95483745376679\n",
      "\n",
      "Epoch 00040: val_f1 did not improve\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0583 - acc: 0.9798 - val_loss: 0.0751 - val_acc: 0.9792\n",
      "recall: 0.9827359501314893 - precision: 0.9700749927891549 - f1: 0.9763644281014128\n",
      "val_recall: 0.9656171527911918 - val_precision: 0.9565633371603521 - val_f1: 0.9610689224262233\n",
      "\n",
      "Epoch 00041: val_f1 did not improve\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0584 - acc: 0.9798 - val_loss: 0.1191 - val_acc: 0.9774\n",
      "recall: 0.982906399142885 - precision: 0.9707565773652062 - f1: 0.9767937084089534\n",
      "val_recall: 0.9644581804133668 - val_precision: 0.9614866165992683 - val_f1: 0.962970106075217\n",
      "\n",
      "Epoch 00042: val_f1 did not improve\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0580 - acc: 0.9800 - val_loss: 0.2206 - val_acc: 0.9290\n",
      "recall: 0.9689539300672056 - precision: 0.9810413687687983 - f1: 0.9749601862060517\n",
      "val_recall: 0.9536411048870002 - val_precision: 0.9674701156182638 - val_f1: 0.9605058365758754\n",
      "\n",
      "Epoch 00043: val_f1 did not improve\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0571 - acc: 0.9800 - val_loss: 0.1414 - val_acc: 0.9707\n",
      "recall: 0.9794730690561995 - precision: 0.9746317115720101 - f1: 0.9770463930046149\n",
      "val_recall: 0.961947073594746 - val_precision: 0.9608334941153772 - val_f1: 0.9613899613899612\n",
      "\n",
      "Epoch 00044: val_f1 did not improve\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0567 - acc: 0.9807 - val_loss: 0.0880 - val_acc: 0.9746\n",
      "recall: 0.9824437518262394 - precision: 0.9692274430671663 - f1: 0.9757908484086293\n",
      "val_recall: 0.9708325284914043 - val_precision: 0.9506336296576509 - val_f1: 0.9606269113149847\n",
      "\n",
      "Epoch 00045: val_f1 did not improve\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0569 - acc: 0.9805 - val_loss: 0.1439 - val_acc: 0.9505\n",
      "recall: 0.9783773254115126 - precision: 0.9776869357860671 - f1: 0.9780320087628553\n",
      "val_recall: 0.9611744253428627 - val_precision: 0.9669646327244462 - val_f1: 0.964060835028577\n",
      "\n",
      "Epoch 00046: val_f1 did not improve\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.0563 - acc: 0.9809 - val_loss: 0.1248 - val_acc: 0.9648\n",
      "recall: 0.9853413850199669 - precision: 0.9691062362295239 - f1: 0.9771563797932966\n",
      "val_recall: 0.9675487734209002 - val_precision: 0.958293476181366 - val_f1: 0.9628988850442136\n",
      "\n",
      "Epoch 00047: val_f1 did not improve\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0563 - acc: 0.9810 - val_loss: 0.0939 - val_acc: 0.9801\n",
      "recall: 0.9822733028148437 - precision: 0.9737610736958988 - f1: 0.9779986665858538\n",
      "val_recall: 0.9679350975468418 - val_precision: 0.9572110792741165 - val_f1: 0.9625432193622743\n",
      "\n",
      "Epoch 00048: val_f1 did not improve\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0547 - acc: 0.9814 - val_loss: 0.0988 - val_acc: 0.9772\n",
      "recall: 0.9778659783773254 - precision: 0.9769857681547257 - f1: 0.9774256751000937\n",
      "val_recall: 0.9590496426501836 - val_precision: 0.9684025746050322 - val_f1: 0.9637034161490684\n",
      "\n",
      "Epoch 00049: val_f1 did not improve\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.0554 - acc: 0.9813 - val_loss: 0.2202 - val_acc: 0.9290\n",
      "recall: 0.9781094769650336 - precision: 0.9783238753988164 - f1: 0.9782166644343517\n",
      "val_recall: 0.9578906702723585 - val_precision: 0.9642232160217772 - val_f1: 0.9610465116279069\n",
      "\n",
      "Epoch 00050: val_f1 did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e9b28d7b8>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "model.fit_generator(\n",
    "    sparse_generator(data_X[split_slices[0]], data_y[split_slices[0]], 1024, shuffle=True),\n",
    "    steps_per_epoch=np.ceil(data_X[split_slices[0]].shape[0] / 1024),\n",
    "    validation_data=sparse_generator(data_X[split_slices[1]], data_y[split_slices[1]], shuffle=False),\n",
    "    validation_steps=np.ceil(data_X[split_slices[1]].shape[0] / 1024),\n",
    "    class_weight=weights,\n",
    "    callbacks=[metrics_train, metrics,  checkpoint, early_stopper],\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/nikitautiu/models/keras/weights.best.hdf5') # load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9749436049191064"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_generator(\n",
    "    sparse_generator(data_X[split_slices[0]], None, 1024, shuffle=False),\n",
    "    steps=np.ceil(data_X[split_slices[0]].shape[0] / 1024)\n",
    ")\n",
    "preds = np.round(preds)\n",
    "f1_score(preds, data_y[split_slices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663354876049001"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_generator(\n",
    "    sparse_generator(data_X[split_slices[1]], None, 1024, shuffle=False),\n",
    "    steps=np.ceil(data_X[split_slices[1]].shape[0] / 1024)\n",
    ")\n",
    "preds = np.round(preds)\n",
    "f1_score(preds, data_y[split_slices[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644556962025316"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_generator(\n",
    "    sparse_generator(data_X[split_slices[2]], None, 1024, shuffle=False),\n",
    "    steps=np.ceil(data_X[split_slices[2]].shape[0] / 1024)\n",
    ")\n",
    "preds = np.round(preds)\n",
    "f1_score(preds, data_y[split_slices[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn compatible model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_block = dataset['is_block'].ravel()\n",
    "# data_X = RecDict({'numeric': dataset['numeric'][is_block], 'text': dataset['text'][is_block, 0]})\n",
    "# data_y = dataset['y'][is_block]\n",
    "# groups = dataset['id'][is_block, 0]  # for the url\n",
    "\n",
    "is_block = dataset['is_block'].ravel()\n",
    "data_X = RecDict({'numeric': dataset['numeric'][:], 'text': dataset['text'][:, 0]})\n",
    "data_y = dataset['y'][:]\n",
    "groups = dataset['id'][:, 0]  # for the url\n",
    "\n",
    "# order them by group, for consistency\n",
    "order = group_argsort(groups)\n",
    "groups = groups[order]\n",
    "data_X = data_X[order]\n",
    "data_y = data_y[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([      0,       1,       2, ..., 1085425, 1085426, 1085427]),\n",
       " array([  12267,   12268,   12269, ..., 1082103, 1082104, 1082105])]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the split slices(just train, test - the validation is split in the estimator)\n",
    "splitter = GroupKFold(10).split(data_X, data_y, groups)\n",
    "split_slices = [0, 0]\n",
    "split_slices[1] = next(splitter)[1]\n",
    "\n",
    "split_slices[0] = np.ones(data_X.shape[0], dtype=bool)\n",
    "split_slices[0][split_slices[1]] = False\n",
    "split_slices[0] = np.nonzero(split_slices[0])[0]\n",
    "\n",
    "split_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "estimator = MyKerasClassifier(create_model, shuffle=True,\n",
    "                        hidden_layers=[1000, 500, 100],\n",
    "                        optimizer='rmsprop', dropout=.2, activation='relu',\n",
    "                        class_weight='balanced', epochs=25, patience=200)\n",
    "\n",
    "# define the pipeline\n",
    "# FeatureUnion gives \n",
    "est = Pipeline(steps=[\n",
    "    ('union', FeatureUnion(transformer_list=[\n",
    "        ('numeric', Pipeline(steps=[\n",
    "            ('select', ItemSelector(key='numeric')),\n",
    "        ])),\n",
    "        ('class', Pipeline(steps=[\n",
    "            ('select', ItemSelector(key='text')),\n",
    "            ('text', TfidfVectorizer(analyzer='char_wb', ngram_range=(3,3), use_idf=False,\n",
    "                                     preprocessor=preprocess_text))\n",
    "        ]))],\n",
    "        transformer_weights={\n",
    "            'numeric': 1.0,\n",
    "            'class': 1.0\n",
    "        },\n",
    "    )),\n",
    "    ('normalizer', MaxAbsScaler()),\n",
    "    ('classify', estimator)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "859/859 [==============================] - 167s 194ms/step - loss: 0.0875 - acc: 0.9726 - val_loss: 0.1273 - val_acc: 0.9519\n",
      "val_recall: 0.8694571073352673 - val_precision: 0.6218138707765264 - val_f1: 0.725073440470019\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.72507, saving model to /tmp/tmpvib_42tl\n",
      "Epoch 2/25\n",
      "859/859 [==============================] - 166s 194ms/step - loss: 0.0632 - acc: 0.9802 - val_loss: 0.1112 - val_acc: 0.9684\n",
      "val_recall: 0.8547451305428927 - val_precision: 0.5920769341179848 - val_f1: 0.699567540066141\n",
      "\n",
      "Epoch 00002: val_f1 did not improve\n",
      "Epoch 3/25\n",
      "859/859 [==============================] - 183s 213ms/step - loss: 0.0604 - acc: 0.9820 - val_loss: 0.1414 - val_acc: 0.9475\n",
      "val_recall: 0.9094488188976378 - val_precision: 0.657331136738056 - val_f1: 0.763105276884291\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.72507 to 0.76311, saving model to /tmp/tmpvib_42tl\n",
      "Epoch 4/25\n",
      "859/859 [==============================] - 165s 193ms/step - loss: 0.0591 - acc: 0.9833 - val_loss: 0.0433 - val_acc: 0.9906\n",
      "val_recall: 0.8976377952755905 - val_precision: 0.7071498530852106 - val_f1: 0.7910883856829803\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.76311 to 0.79109, saving model to /tmp/tmpvib_42tl\n",
      "Epoch 5/25\n",
      "859/859 [==============================] - 166s 193ms/step - loss: 0.0592 - acc: 0.9838 - val_loss: 0.0569 - val_acc: 0.9790\n",
      "val_recall: 0.8984666390385412 - val_precision: 0.6105322444381864 - val_f1: 0.727028839704896\n",
      "\n",
      "Epoch 00005: val_f1 did not improve\n",
      "Epoch 6/25\n",
      "859/859 [==============================] - 166s 193ms/step - loss: 0.0579 - acc: 0.9843 - val_loss: 0.1011 - val_acc: 0.9732\n",
      "val_recall: 0.8818897637795275 - val_precision: 0.5969144460028051 - val_f1: 0.711943793911007\n",
      "\n",
      "Epoch 00006: val_f1 did not improve\n",
      "Epoch 7/25\n",
      "859/859 [==============================] - 166s 193ms/step - loss: 0.0587 - acc: 0.9847 - val_loss: 0.1369 - val_acc: 0.9742\n",
      "val_recall: 0.9111065064235392 - val_precision: 0.6247513498152885 - val_f1: 0.7412339851652057\n",
      "\n",
      "Epoch 00007: val_f1 did not improve\n",
      "Epoch 8/25\n",
      "859/859 [==============================] - 205s 238ms/step - loss: 0.0585 - acc: 0.9845 - val_loss: 0.1150 - val_acc: 0.9587\n",
      "val_recall: 0.8798176543721509 - val_precision: 0.6760070052539404 - val_f1: 0.7645628882686594\n",
      "\n",
      "Epoch 00008: val_f1 did not improve\n",
      "Epoch 9/25\n",
      "859/859 [==============================] - 167s 194ms/step - loss: 0.0587 - acc: 0.9848 - val_loss: 0.0620 - val_acc: 0.9828\n",
      "val_recall: 0.8553667633651056 - val_precision: 0.6728606356968215 - val_f1: 0.7532159474500502\n",
      "\n",
      "Epoch 00009: val_f1 did not improve\n",
      "Epoch 10/25\n",
      "859/859 [==============================] - 181s 211ms/step - loss: 0.0587 - acc: 0.9852 - val_loss: 0.1059 - val_acc: 0.9718\n",
      "val_recall: 0.868421052631579 - val_precision: 0.6677820267686424 - val_f1: 0.7549990992613942\n",
      "\n",
      "Epoch 00010: val_f1 did not improve\n",
      "Epoch 11/25\n",
      "859/859 [==============================] - 168s 195ms/step - loss: 0.0561 - acc: 0.9854 - val_loss: 0.1203 - val_acc: 0.9644\n",
      "val_recall: 0.8611686697057604 - val_precision: 0.7092150170648465 - val_f1: 0.7778401647014785\n",
      "\n",
      "Epoch 00011: val_f1 did not improve\n",
      "Epoch 12/25\n",
      "859/859 [==============================] - 170s 198ms/step - loss: 0.0570 - acc: 0.9854 - val_loss: 0.0366 - val_acc: 0.9867\n",
      "val_recall: 0.8530874430169912 - val_precision: 0.722280701754386 - val_f1: 0.7822534676040281\n",
      "\n",
      "Epoch 00012: val_f1 did not improve\n",
      "Epoch 13/25\n",
      "859/859 [==============================] - 172s 201ms/step - loss: 0.0605 - acc: 0.9855 - val_loss: 0.1039 - val_acc: 0.9735\n",
      "val_recall: 0.9183588893493576 - val_precision: 0.6393537218695903 - val_f1: 0.7538697057322674\n",
      "\n",
      "Epoch 00013: val_f1 did not improve\n",
      "Epoch 14/25\n",
      "859/859 [==============================] - 173s 201ms/step - loss: 0.0590 - acc: 0.9859 - val_loss: 0.0452 - val_acc: 0.9867\n",
      "val_recall: 0.8648984666390386 - val_precision: 0.7226454293628809 - val_f1: 0.7873986040369743\n",
      "\n",
      "Epoch 00014: val_f1 did not improve\n",
      "Epoch 15/25\n",
      "859/859 [==============================] - 170s 198ms/step - loss: 0.0592 - acc: 0.9858 - val_loss: 0.1221 - val_acc: 0.9699\n",
      "val_recall: 0.8762950683796105 - val_precision: 0.6788121990369181 - val_f1: 0.7650144717800289\n",
      "\n",
      "Epoch 00015: val_f1 did not improve\n",
      "Epoch 16/25\n",
      "859/859 [==============================] - 172s 200ms/step - loss: 0.0587 - acc: 0.9859 - val_loss: 0.0909 - val_acc: 0.9711\n",
      "val_recall: 0.8802320762536262 - val_precision: 0.6580945003872967 - val_f1: 0.7531247229855509\n",
      "\n",
      "Epoch 00016: val_f1 did not improve\n",
      "Epoch 17/25\n",
      "859/859 [==============================] - 169s 196ms/step - loss: 0.0585 - acc: 0.9858 - val_loss: 0.0789 - val_acc: 0.9785\n",
      "val_recall: 0.8628263572316618 - val_precision: 0.7315530569219958 - val_f1: 0.7917855105533372\n",
      "\n",
      "Epoch 00017: val_f1 improved from 0.79109 to 0.79179, saving model to /tmp/tmpvib_42tl\n",
      "Epoch 18/25\n",
      "859/859 [==============================] - 180s 209ms/step - loss: 0.0586 - acc: 0.9858 - val_loss: 0.1196 - val_acc: 0.9709\n",
      "val_recall: 0.8568172399502694 - val_precision: 0.7900267481849446 - val_f1: 0.8220675944333996\n",
      "\n",
      "Epoch 00018: val_f1 improved from 0.79179 to 0.82207, saving model to /tmp/tmpvib_42tl\n",
      "Epoch 19/25\n",
      "859/859 [==============================] - 169s 197ms/step - loss: 0.0589 - acc: 0.9862 - val_loss: 0.0469 - val_acc: 0.9857\n",
      "val_recall: 0.8713220058019063 - val_precision: 0.6503247757500773 - val_f1: 0.74477506199079\n",
      "\n",
      "Epoch 00019: val_f1 did not improve\n",
      "Epoch 20/25\n",
      "859/859 [==============================] - 172s 200ms/step - loss: 0.0601 - acc: 0.9862 - val_loss: 0.0455 - val_acc: 0.9813\n",
      "val_recall: 0.9736842105263158 - val_precision: 0.6298083366840906 - val_f1: 0.7648734434768455\n",
      "\n",
      "Epoch 00020: val_f1 did not improve\n",
      "Epoch 21/25\n",
      "859/859 [==============================] - 169s 197ms/step - loss: 0.0574 - acc: 0.9866 - val_loss: 0.0933 - val_acc: 0.9705\n",
      "val_recall: 0.9135930377123912 - val_precision: 0.5976684289006371 - val_f1: 0.7226091944603785\n",
      "\n",
      "Epoch 00021: val_f1 did not improve\n",
      "Epoch 22/25\n",
      "859/859 [==============================] - 437s 509ms/step - loss: 0.0593 - acc: 0.9864 - val_loss: 0.1129 - val_acc: 0.9770\n",
      "val_recall: 0.9082055532532117 - val_precision: 0.644748455428067 - val_f1: 0.7541293874741913\n",
      "\n",
      "Epoch 00022: val_f1 did not improve\n",
      "Epoch 23/25\n",
      "859/859 [==============================] - 246s 286ms/step - loss: 0.0584 - acc: 0.9864 - val_loss: 0.1086 - val_acc: 0.9529\n",
      "val_recall: 0.9635308744301699 - val_precision: 0.5579553635709144 - val_f1: 0.7066869300911854\n",
      "\n",
      "Epoch 00023: val_f1 did not improve\n",
      "Epoch 24/25\n",
      "859/859 [==============================] - 261s 304ms/step - loss: 0.0619 - acc: 0.9858 - val_loss: 0.1150 - val_acc: 0.9675\n",
      "val_recall: 0.9177372565271447 - val_precision: 0.5823034446489613 - val_f1: 0.7125160875160875\n",
      "\n",
      "Epoch 00024: val_f1 did not improve\n",
      "Epoch 25/25\n",
      "859/859 [==============================] - 882s 1s/step - loss: 0.0620 - acc: 0.9862 - val_loss: 0.1218 - val_acc: 0.9577\n",
      "val_recall: 0.8615830915872358 - val_precision: 0.7059422750424448 - val_f1: 0.7760358342665173\n",
      "\n",
      "Epoch 00025: val_f1 did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(memory=None, steps=[('select', ItemSelector(key='numeric'))])), ('class', Pipeline(memory=None,\n",
       "     steps=[('select', ItemSelector(key='text')), ('text', TfidfVectorizer(analyzer='char_wb', binary=False, decode_er...alizer', MaxAbsScaler(copy=True)), ('classify', <utils.MyKerasClassifier object at 0x7f4e232a5710>)])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(data_X[split_slices[0]], data_y[split_slices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902261108529168"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(est.predict(data_X[split_slices[0]]), data_y[split_slices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8903566710700132"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(est.predict(data_X[split_slices[1]]), data_y[split_slices[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
