{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the csv pipeline and the cleaneval dataset to train a model with a weighted cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# standard library\n",
    "import itertools\n",
    "import sys, os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from collections import OrderedDict\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# tesnsorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# local imports\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "from tf_utils import make_csv_pipeline, make_csv_col_tensors\n",
    "\n",
    "# this styling is purely my preference\n",
    "# less chartjunk\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'line.linewidth': 2.5})\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>sibling_pos</th>\n",
       "      <th>no_classes</th>\n",
       "      <th>id_len</th>\n",
       "      <th>class_len</th>\n",
       "      <th>no_children</th>\n",
       "      <th>text_len</th>\n",
       "      <th>descendant1_no_nodes</th>\n",
       "      <th>descendant1_no_children_avg</th>\n",
       "      <th>descendant1_id_len_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>ancestor5_tag_content_area</th>\n",
       "      <th>ancestor5_tag_layer</th>\n",
       "      <th>ancestor5_tag_defanged_meta</th>\n",
       "      <th>ancestor5_tag_storysumm</th>\n",
       "      <th>ancestor5_tag_beginlock</th>\n",
       "      <th>ancestor5_tag_endlock</th>\n",
       "      <th>ancestor5_tag_dt</th>\n",
       "      <th>ancestor5_tag_noedit</th>\n",
       "      <th>ancestor5_tag_small</th>\n",
       "      <th>content_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>8594</td>\n",
       "      <td>67</td>\n",
       "      <td>1.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  sibling_pos  no_classes  id_len  class_len  no_children  text_len  \\\n",
       "0      3            0           0      69          0           67      8594   \n",
       "1      5            0           0       0          0            0        19   \n",
       "2      4           33           0       0          0            0         0   \n",
       "3      5           10           0       0          0            0       107   \n",
       "4      5            2           0       0          0            1         5   \n",
       "\n",
       "   descendant1_no_nodes  descendant1_no_children_avg  descendant1_id_len_avg  \\\n",
       "0                    67                     1.014925                     0.0   \n",
       "1                     0                     0.000000                     0.0   \n",
       "2                     0                     0.000000                     0.0   \n",
       "3                     0                     0.000000                     0.0   \n",
       "4                     1                     0.000000                     0.0   \n",
       "\n",
       "       ...        ancestor5_tag_content_area  ancestor5_tag_layer  \\\n",
       "0      ...                                 0                    0   \n",
       "1      ...                                 0                    0   \n",
       "2      ...                                 0                    0   \n",
       "3      ...                                 0                    0   \n",
       "4      ...                                 0                    0   \n",
       "\n",
       "   ancestor5_tag_defanged_meta  ancestor5_tag_storysumm  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   ancestor5_tag_beginlock  ancestor5_tag_endlock  ancestor5_tag_dt  \\\n",
       "0                        0                      0                 0   \n",
       "1                        0                      0                 0   \n",
       "2                        0                      0                 0   \n",
       "3                        0                      0                 0   \n",
       "4                        0                      0                 0   \n",
       "\n",
       "   ancestor5_tag_noedit  ancestor5_tag_small  content_label  \n",
       "0                     0                    0          False  \n",
       "1                     0                    0          False  \n",
       "2                     0                    0          False  \n",
       "3                     0                    0           True  \n",
       "4                     0                    0           True  \n",
       "\n",
       "[5 rows x 1575 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ddf = dd.read_csv('../data/final/cleaneval/dom-full-train-*.csv')\n",
    "train_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the label proportion \n",
    "label_proportion = train_ddf['content_label'].mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature and label names\n",
    "label_names = ['content_label']\n",
    "feature_names = set(train_ddf.columns) - set(['content_label', 'url', 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# define the input function\n",
    "def input_fn(csv_pattern, **kws):\n",
    "    train_ddf = dd.read_csv(csv_pattern)\n",
    "    # get the cols\n",
    "    label_names = ['content_label']\n",
    "    feature_names = set(train_ddf.columns) - set(['content_label', 'url', 'path'])\n",
    "    \n",
    "    # get the weight\n",
    "    label_proportion = train_ddf['content_label'].mean().compute()\n",
    "    \n",
    "    # get the tensors\n",
    "    feature_tens, label_tens, = make_csv_pipeline(csv_pattern=csv_pattern, feature_cols=feature_names, label_cols=label_names, **kws)\n",
    "    \n",
    "    batch_size = kws.get('batch_size')\n",
    "    weight_tens = tf.where(tf.equal(label_tens, tf.constant(1.0)), \n",
    "                           tf.constant(0.5 / label_proportion, shape=(batch_size, 1)), \n",
    "                           tf.constant(0.5 / (1-label_proportion), shape=(batch_size, 1)))\n",
    "    return {'x': feature_tens, 'weights': weight_tens}, label_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'weights': <tf.Tensor 'Select_3:0' shape=(100, 1) dtype=float64>,\n",
       "  'x': <tf.Tensor 'input_pipeline_2/shuffle_batch:0' shape=(100, 1572) dtype=float32>},\n",
       " <tf.Tensor 'input_pipeline_2/shuffle_batch:1' shape=(100, 1) dtype=float32>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn('../data/final/cleaneval/dom-full-*.csv', num_epochs=2000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwssl10o3\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f549725acf8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpwssl10o3'}\n"
     ]
    }
   ],
   "source": [
    "tf_feat_cols = [\n",
    "    tf.feature_column.numeric_column('x', shape=(1572)),\n",
    "    tf.feature_column.numeric_column('weights')\n",
    "]\n",
    "estiamtor = tf.contrib.learn.DNNClassifier(feature_columns=tf_feat_cols, hidden_units=(1000, 500, 200), weight_column_name='weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpwssl10o3/model.ckpt.\n",
      "INFO:tensorflow:loss = 120.992, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.37004\n",
      "INFO:tensorflow:loss = 27.2559, step = 101 (42.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34483\n",
      "INFO:tensorflow:loss = 1.6135, step = 201 (42.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34563\n",
      "INFO:tensorflow:loss = 3.53141, step = 301 (42.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34866\n",
      "INFO:tensorflow:loss = 5.5612, step = 401 (42.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.35208\n",
      "INFO:tensorflow:loss = 1.20969, step = 501 (42.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34289\n",
      "INFO:tensorflow:loss = 3.20536, step = 601 (42.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.3406\n",
      "INFO:tensorflow:loss = 0.790838, step = 701 (42.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.3442\n",
      "INFO:tensorflow:loss = 0.839722, step = 801 (42.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34593\n",
      "INFO:tensorflow:loss = 1.96416, step = 901 (42.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.35298\n",
      "INFO:tensorflow:loss = 0.88609, step = 1001 (42.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34511\n",
      "INFO:tensorflow:loss = 2.34973, step = 1101 (42.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34814\n",
      "INFO:tensorflow:loss = 0.680814, step = 1201 (42.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.35757\n",
      "INFO:tensorflow:loss = 1.04812, step = 1301 (42.416 sec)\n"
     ]
    }
   ],
   "source": [
    "estiamtor.fit(input_fn=lambda: input_fn('../data/final/cleaneval/dom-full-train-*.csv', num_epochs=2000, batch_size=100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-31-07:30:41\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpwssl10o3/model.ckpt-61973\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-31-07:56:12\n",
      "INFO:tensorflow:Saving dict for global step 61973: accuracy = 0.750584, accuracy/baseline_label_mean = 0.499997, accuracy/threshold_0.500000_mean = 0.750584, auc = 0.837838, auc_precision_recall = 0.811292, global_step = 61973, labels/actual_label_mean = 0.499997, labels/prediction_mean = 0.458518, loss = 0.4874, precision/positive_threshold_0.500000_mean = 0.754067, recall/positive_threshold_0.500000_mean = 0.743729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75058401,\n",
       " 'accuracy/baseline_label_mean': 0.49999663,\n",
       " 'accuracy/threshold_0.500000_mean': 0.75058401,\n",
       " 'auc': 0.83783799,\n",
       " 'auc_precision_recall': 0.81129247,\n",
       " 'global_step': 61973,\n",
       " 'labels/actual_label_mean': 0.49999663,\n",
       " 'labels/prediction_mean': 0.45851752,\n",
       " 'loss': 0.48740026,\n",
       " 'precision/positive_threshold_0.500000_mean': 0.75406724,\n",
       " 'recall/positive_threshold_0.500000_mean': 0.74372864}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estiamtor.evaluate(input_fn=lambda: input_fn('../data/final/cleaneval/dom-full-train-*.csv', num_epochs=1, batch_size=1000, shuffle=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-31-07:18:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpwssl10o3/model.ckpt-61973\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-31-07:24:01\n",
      "INFO:tensorflow:Saving dict for global step 61973: accuracy = 0.695138, accuracy/baseline_label_mean = 0.49904, accuracy/threshold_0.500000_mean = 0.695138, auc = 0.782362, auc_precision_recall = 0.74415, global_step = 61973, labels/actual_label_mean = 0.49904, labels/prediction_mean = 0.454101, loss = 0.557717, precision/positive_threshold_0.500000_mean = 0.704906, recall/positive_threshold_0.500000_mean = 0.669281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.69513828,\n",
       " 'accuracy/baseline_label_mean': 0.49903956,\n",
       " 'accuracy/threshold_0.500000_mean': 0.69513828,\n",
       " 'auc': 0.78236204,\n",
       " 'auc_precision_recall': 0.74414968,\n",
       " 'global_step': 61973,\n",
       " 'labels/actual_label_mean': 0.49903956,\n",
       " 'labels/prediction_mean': 0.45410097,\n",
       " 'loss': 0.55771714,\n",
       " 'precision/positive_threshold_0.500000_mean': 0.70490563,\n",
       " 'recall/positive_threshold_0.500000_mean': 0.66928065}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estiamtor.evaluate(input_fn=lambda: input_fn('../data/final/cleaneval/dom-full-test-*.csv', num_epochs=1, batch_size=1000, shuffle=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
